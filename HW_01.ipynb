{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9549, 0.8938, 0.5840, 0.7678, 0.3593],\n",
       "         [0.9655, 0.7123, 0.0836, 0.1693, 0.6652],\n",
       "         [0.3330, 0.3163, 0.0122, 0.5328, 0.9736],\n",
       "         [0.0581, 0.6228, 0.1091, 0.7425, 0.5461]],\n",
       "\n",
       "        [[0.2329, 0.8115, 0.3756, 0.8587, 0.7729],\n",
       "         [0.5903, 0.1356, 0.2232, 0.8219, 0.5439],\n",
       "         [0.0907, 0.7935, 0.9113, 0.8699, 0.1380],\n",
       "         [0.9320, 0.6955, 0.2343, 0.9488, 0.9204]],\n",
       "\n",
       "        [[0.2819, 0.0668, 0.0590, 0.9475, 0.0272],\n",
       "         [0.5054, 0.0165, 0.8700, 0.3811, 0.6853],\n",
       "         [0.4413, 0.4697, 0.1586, 0.3558, 0.7662],\n",
       "         [0.7092, 0.5692, 0.1097, 0.3709, 0.1713]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте случайный FloatTensor размера 3x4x5\n",
    "x = torch.rand(3, 4, 5, dtype=torch.float) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Выведите его форму (shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9549, 0.8938, 0.5840, 0.7678, 0.3593, 0.9655, 0.7123, 0.0836, 0.1693,\n",
       "         0.6652],\n",
       "        [0.3330, 0.3163, 0.0122, 0.5328, 0.9736, 0.0581, 0.6228, 0.1091, 0.7425,\n",
       "         0.5461],\n",
       "        [0.2329, 0.8115, 0.3756, 0.8587, 0.7729, 0.5903, 0.1356, 0.2232, 0.8219,\n",
       "         0.5439],\n",
       "        [0.0907, 0.7935, 0.9113, 0.8699, 0.1380, 0.9320, 0.6955, 0.2343, 0.9488,\n",
       "         0.9204],\n",
       "        [0.2819, 0.0668, 0.0590, 0.9475, 0.0272, 0.5054, 0.0165, 0.8700, 0.3811,\n",
       "         0.6853],\n",
       "        [0.4413, 0.4697, 0.1586, 0.3558, 0.7662, 0.7092, 0.5692, 0.1097, 0.3709,\n",
       "         0.1713]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Приведите его к форме 6 X 10\n",
    "x1 = x.reshape(6, 10)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9316/318573177.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Умножьте его на вектор [1, 4, 2, 2, 1] поэлементно\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Умножьте его на вектор [1, 4, 2, 2, 1] поэлементно\n",
    "x2 = x1 * torch.tensor([1, 4, 2, 2, 1])\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9549, 3.5754, 1.1680, 1.5355, 0.3593, 0.9655, 2.8493, 0.1672, 0.3385,\n",
       "         0.6652],\n",
       "        [0.3330, 1.2650, 0.0245, 1.0655, 0.9736, 0.0581, 2.4913, 0.2182, 1.4850,\n",
       "         0.5461],\n",
       "        [0.2329, 3.2461, 0.7512, 1.7174, 0.7729, 0.5903, 0.5425, 0.4463, 1.6438,\n",
       "         0.5439],\n",
       "        [0.0907, 3.1741, 1.8225, 1.7398, 0.1380, 0.9320, 2.7821, 0.4686, 1.8977,\n",
       "         0.9204],\n",
       "        [0.2819, 0.2674, 0.1180, 1.8951, 0.0272, 0.5054, 0.0662, 1.7399, 0.7622,\n",
       "         0.6853],\n",
       "        [0.4413, 1.8787, 0.3172, 0.7116, 0.7662, 0.7092, 2.2770, 0.2193, 0.7418,\n",
       "         0.1713]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ^^ такой вариант не сработал, последняя размерность должна совпадать с размером вектора, приведем к подходящей форме и обратно\n",
    "# Умножьте его на вектор [1, 4, 2, 2, 1] поэлементно\n",
    "x2 = (x1.reshape(12, 5) * torch.tensor([1, 4, 2, 2, 1])).reshape(6, 10)\n",
    "print(x2.shape)\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[27.1823, 14.9124, 18.7294, 26.4449,  5.9640, 16.4511],\n",
       "        [14.9124, 12.5559, 11.0060, 16.4862,  4.5606, 10.9922],\n",
       "        [18.7294, 11.0060, 18.5426, 20.6769,  7.0342, 11.3182],\n",
       "        [26.4449, 16.4862, 20.6769, 29.7272,  7.9378, 16.5888],\n",
       "        [ 5.9640,  4.5606,  7.0342,  7.9378,  8.0947,  3.6071],\n",
       "        [16.4511, 10.9922, 11.3182, 16.5888,  3.6071, 11.2334]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Умножьте тензор матрично на себя, чтобы результат был размерности 6x6\n",
    "x3 = x2 @ x2.T\n",
    "print(x3.shape)\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-148.5000], grad_fn=<SubBackward0>)\n",
      "None None None\n",
      "tensor([3.]) tensor([1.]) tensor([-75.])\n"
     ]
    }
   ],
   "source": [
    "# Посчитайте производную функции y = x**3 + z - 75t в точке (1, 0.5, 2)\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(torch.tensor([1.]), requires_grad = True)\n",
    "z = Variable(torch.tensor([0.5]), requires_grad = True)\n",
    "t = Variable(torch.tensor([2.]), requires_grad = True)\n",
    "\n",
    "y = x**3 + z - 75 * t\n",
    "print(y)\n",
    "print(x.grad, z.grad, t.grad)\n",
    "y.backward()\n",
    "print(x.grad, z.grad, t.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создайте единичный тензор размера 5x6\n",
    "x = torch.ones(5, 6)\n",
    "print(x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Переведите его в формат numpy\n",
    "xnp = x.numpy()\n",
    "print(xnp.shape)\n",
    "xnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([2., 2., 3.])\n",
      "y =  tensor([ 5.,  5., 14.])\n",
      "------- итерация 0 ------------------\n",
      "w1= tensor([1.], requires_grad=True) , pred =  tensor([ -1.,  -1., -10.], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(216., grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-63.8237])\n",
      "------- итерация 1 ------------------\n",
      "w1= tensor([1.0100], requires_grad=True) , pred =  tensor([-0.9861, -0.9861, -9.9669], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(215.3589, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-64.3839])\n",
      "------- итерация 2 ------------------\n",
      "w1= tensor([1.0200], requires_grad=True) , pred =  tensor([-0.9721, -0.9721, -9.9333], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(214.7122, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-64.9482])\n",
      "------- итерация 3 ------------------\n",
      "w1= tensor([1.0300], requires_grad=True) , pred =  tensor([-0.9580, -0.9580, -9.8995], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(214.0595, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-65.5166])\n",
      "------- итерация 4 ------------------\n",
      "w1= tensor([1.0400], requires_grad=True) , pred =  tensor([-0.9437, -0.9437, -9.8652], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(213.4007, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-66.0894])\n",
      "------- итерация 5 ------------------\n",
      "w1= tensor([1.0500], requires_grad=True) , pred =  tensor([-0.9294, -0.9294, -9.8305], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(212.7358, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-66.6665])\n",
      "------- итерация 6 ------------------\n",
      "w1= tensor([1.0601], requires_grad=True) , pred =  tensor([-0.9150, -0.9150, -9.7954], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(212.0646, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-67.2480])\n",
      "------- итерация 7 ------------------\n",
      "w1= tensor([1.0701], requires_grad=True) , pred =  tensor([-0.9004, -0.9004, -9.7598], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(211.3868, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-67.8341])\n",
      "------- итерация 8 ------------------\n",
      "w1= tensor([1.0801], requires_grad=True) , pred =  tensor([-0.8858, -0.8858, -9.7239], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(210.7024, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-68.4249])\n",
      "------- итерация 9 ------------------\n",
      "w1= tensor([1.0902], requires_grad=True) , pred =  tensor([-0.8710, -0.8710, -9.6875], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(210.0113, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-69.0204])\n",
      "------- итерация 10 ------------------\n",
      "w1= tensor([1.1003], requires_grad=True) , pred =  tensor([-0.8561, -0.8561, -9.6506], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(209.3132, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-69.6207])\n",
      "------- итерация 11 ------------------\n",
      "w1= tensor([1.1104], requires_grad=True) , pred =  tensor([-0.8410, -0.8410, -9.6133], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(208.6080, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-70.2259])\n",
      "------- итерация 12 ------------------\n",
      "w1= tensor([1.1205], requires_grad=True) , pred =  tensor([-0.8258, -0.8258, -9.5755], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(207.8956, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-70.8361])\n",
      "------- итерация 13 ------------------\n",
      "w1= tensor([1.1306], requires_grad=True) , pred =  tensor([-0.8105, -0.8105, -9.5373], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(207.1758, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-71.4514])\n",
      "------- итерация 14 ------------------\n",
      "w1= tensor([1.1407], requires_grad=True) , pred =  tensor([-0.7951, -0.7951, -9.4985], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(206.4484, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-72.0718])\n",
      "------- итерация 15 ------------------\n",
      "w1= tensor([1.1509], requires_grad=True) , pred =  tensor([-0.7795, -0.7795, -9.4592], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(205.7133, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-72.6975])\n",
      "------- итерация 16 ------------------\n",
      "w1= tensor([1.1610], requires_grad=True) , pred =  tensor([-0.7638, -0.7638, -9.4194], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(204.9703, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-73.3285])\n",
      "------- итерация 17 ------------------\n",
      "w1= tensor([1.1712], requires_grad=True) , pred =  tensor([-0.7480, -0.7480, -9.3790], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(204.2193, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-73.9650])\n",
      "------- итерация 18 ------------------\n",
      "w1= tensor([1.1815], requires_grad=True) , pred =  tensor([-0.7319, -0.7319, -9.3382], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(203.4600, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-74.6069])\n",
      "------- итерация 19 ------------------\n",
      "w1= tensor([1.1917], requires_grad=True) , pred =  tensor([-0.7158, -0.7158, -9.2967], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(202.6925, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-75.2544])\n",
      "------- итерация 20 ------------------\n",
      "w1= tensor([1.2020], requires_grad=True) , pred =  tensor([-0.6995, -0.6995, -9.2547], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(201.9163, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-75.9076])\n",
      "------- итерация 21 ------------------\n",
      "w1= tensor([1.2123], requires_grad=True) , pred =  tensor([-0.6830, -0.6830, -9.2121], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(201.1315, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-76.5664])\n",
      "------- итерация 22 ------------------\n",
      "w1= tensor([1.2226], requires_grad=True) , pred =  tensor([-0.6664, -0.6664, -9.1689], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(200.3378, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-77.2311])\n",
      "------- итерация 23 ------------------\n",
      "w1= tensor([1.2329], requires_grad=True) , pred =  tensor([-0.6496, -0.6496, -9.1251], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(199.5352, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-77.9015])\n",
      "------- итерация 24 ------------------\n",
      "w1= tensor([1.2433], requires_grad=True) , pred =  tensor([-0.6326, -0.6326, -9.0807], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(198.7233, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-78.5779])\n",
      "------- итерация 25 ------------------\n",
      "w1= tensor([1.2537], requires_grad=True) , pred =  tensor([-0.6154, -0.6154, -9.0356], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(197.9021, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-79.2603])\n",
      "------- итерация 26 ------------------\n",
      "w1= tensor([1.2642], requires_grad=True) , pred =  tensor([-0.5981, -0.5981, -8.9899], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(197.0714, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-79.9486])\n",
      "------- итерация 27 ------------------\n",
      "w1= tensor([1.2746], requires_grad=True) , pred =  tensor([-0.5807, -0.5807, -8.9435], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(196.2310, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-80.6431])\n",
      "------- итерация 28 ------------------\n",
      "w1= tensor([1.2851], requires_grad=True) , pred =  tensor([-0.5630, -0.5630, -8.8965], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(195.3808, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-81.3436])\n",
      "------- итерация 29 ------------------\n",
      "w1= tensor([1.2956], requires_grad=True) , pred =  tensor([-0.5451, -0.5451, -8.8487], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(194.5207, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-82.0504])\n",
      "------- итерация 30 ------------------\n",
      "w1= tensor([1.3062], requires_grad=True) , pred =  tensor([-0.5271, -0.5271, -8.8003], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(193.6503, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-82.7633])\n",
      "------- итерация 31 ------------------\n",
      "w1= tensor([1.3168], requires_grad=True) , pred =  tensor([-0.5089, -0.5089, -8.7511], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(192.7697, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-83.4825])\n",
      "------- итерация 32 ------------------\n",
      "w1= tensor([1.3274], requires_grad=True) , pred =  tensor([-0.4905, -0.4905, -8.7012], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(191.8786, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-84.2079])\n",
      "------- итерация 33 ------------------\n",
      "w1= tensor([1.3381], requires_grad=True) , pred =  tensor([-0.4718, -0.4718, -8.6506], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(190.9769, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-84.9396])\n",
      "------- итерация 34 ------------------\n",
      "w1= tensor([1.3488], requires_grad=True) , pred =  tensor([-0.4530, -0.4530, -8.5992], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(190.0644, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-85.6777])\n",
      "------- итерация 35 ------------------\n",
      "w1= tensor([1.3595], requires_grad=True) , pred =  tensor([-0.4340, -0.4340, -8.5470], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(189.1410, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-86.4221])\n",
      "------- итерация 36 ------------------\n",
      "w1= tensor([1.3703], requires_grad=True) , pred =  tensor([-0.4148, -0.4148, -8.4940], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(188.2064, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-87.1728])\n",
      "------- итерация 37 ------------------\n",
      "w1= tensor([1.3811], requires_grad=True) , pred =  tensor([-0.3954, -0.3954, -8.4402], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(187.2606, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-87.9299])\n",
      "------- итерация 38 ------------------\n",
      "w1= tensor([1.3919], requires_grad=True) , pred =  tensor([-0.3757, -0.3757, -8.3856], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(186.3034, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-88.6933])\n",
      "------- итерация 39 ------------------\n",
      "w1= tensor([1.4028], requires_grad=True) , pred =  tensor([-0.3559, -0.3559, -8.3301], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(185.3347, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-89.4631])\n",
      "------- итерация 40 ------------------\n",
      "w1= tensor([1.4137], requires_grad=True) , pred =  tensor([-0.3358, -0.3358, -8.2738], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(184.3542, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-90.2392])\n",
      "------- итерация 41 ------------------\n",
      "w1= tensor([1.4247], requires_grad=True) , pred =  tensor([-0.3155, -0.3155, -8.2166], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(183.3618, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-91.0217])\n",
      "------- итерация 42 ------------------\n",
      "w1= tensor([1.4357], requires_grad=True) , pred =  tensor([-0.2950, -0.2950, -8.1585], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(182.3574, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-91.8104])\n",
      "------- итерация 43 ------------------\n",
      "w1= tensor([1.4467], requires_grad=True) , pred =  tensor([-0.2742, -0.2742, -8.0995], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(181.3408, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-92.6054])\n",
      "------- итерация 44 ------------------\n",
      "w1= tensor([1.4577], requires_grad=True) , pred =  tensor([-0.2532, -0.2532, -8.0396], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(180.3119, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-93.4066])\n",
      "------- итерация 45 ------------------\n",
      "w1= tensor([1.4688], requires_grad=True) , pred =  tensor([-0.2320, -0.2320, -7.9787], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(179.2705, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-94.2140])\n",
      "------- итерация 46 ------------------\n",
      "w1= tensor([1.4800], requires_grad=True) , pred =  tensor([-0.2106, -0.2106, -7.9169], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(178.2164, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-95.0275])\n",
      "------- итерация 47 ------------------\n",
      "w1= tensor([1.4912], requires_grad=True) , pred =  tensor([-0.1889, -0.1889, -7.8541], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(177.1497, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-95.8471])\n",
      "------- итерация 48 ------------------\n",
      "w1= tensor([1.5024], requires_grad=True) , pred =  tensor([-0.1669, -0.1669, -7.7903], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(176.0700, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-96.6727])\n",
      "------- итерация 49 ------------------\n",
      "w1= tensor([1.5136], requires_grad=True) , pred =  tensor([-0.1447, -0.1447, -7.7255], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(174.9772, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-97.5042])\n",
      "------- итерация 50 ------------------\n",
      "w1= tensor([1.5249], requires_grad=True) , pred =  tensor([-0.1223, -0.1223, -7.6596], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(173.8712, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-98.3415])\n",
      "------- итерация 51 ------------------\n",
      "w1= tensor([1.5363], requires_grad=True) , pred =  tensor([-0.0996, -0.0996, -7.5927], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(172.7519, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-99.1845])\n",
      "------- итерация 52 ------------------\n",
      "w1= tensor([1.5476], requires_grad=True) , pred =  tensor([-0.0766, -0.0766, -7.5247], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(171.6191, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-100.0332])\n",
      "------- итерация 53 ------------------\n",
      "w1= tensor([1.5590], requires_grad=True) , pred =  tensor([-0.0534, -0.0534, -7.4556], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(170.4727, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-100.8874])\n",
      "------- итерация 54 ------------------\n",
      "w1= tensor([1.5705], requires_grad=True) , pred =  tensor([-0.0299, -0.0299, -7.3854], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(169.3125, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-101.7469])\n",
      "------- итерация 55 ------------------\n",
      "w1= tensor([1.5820], requires_grad=True) , pred =  tensor([-6.1884e-03, -6.1884e-03, -7.3141e+00], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(168.1385, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-102.6117])\n",
      "------- итерация 56 ------------------\n",
      "w1= tensor([1.5935], requires_grad=True) , pred =  tensor([ 0.0178,  0.0178, -7.2416], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(166.9505, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-103.4816])\n",
      "------- итерация 57 ------------------\n",
      "w1= tensor([1.6051], requires_grad=True) , pred =  tensor([ 0.0421,  0.0421, -7.1680], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(165.7483, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-104.3564])\n",
      "------- итерация 58 ------------------\n",
      "w1= tensor([1.6167], requires_grad=True) , pred =  tensor([ 0.0667,  0.0667, -7.0931], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(164.5318, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-105.2359])\n",
      "------- итерация 59 ------------------\n",
      "w1= tensor([1.6283], requires_grad=True) , pred =  tensor([ 0.0916,  0.0916, -7.0171], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(163.3010, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-106.1200])\n",
      "------- итерация 60 ------------------\n",
      "w1= tensor([1.6400], requires_grad=True) , pred =  tensor([ 0.1167,  0.1167, -6.9398], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(162.0558, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-107.0085])\n",
      "------- итерация 61 ------------------\n",
      "w1= tensor([1.6517], requires_grad=True) , pred =  tensor([ 0.1421,  0.1421, -6.8612], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(160.7959, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-107.9011])\n",
      "------- итерация 62 ------------------\n",
      "w1= tensor([1.6635], requires_grad=True) , pred =  tensor([ 0.1679,  0.1679, -6.7814], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(159.5213, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-108.7977])\n",
      "------- итерация 63 ------------------\n",
      "w1= tensor([1.6753], requires_grad=True) , pred =  tensor([ 0.1939,  0.1939, -6.7002], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(158.2319, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-109.6978])\n",
      "------- итерация 64 ------------------\n",
      "w1= tensor([1.6872], requires_grad=True) , pred =  tensor([ 0.2202,  0.2202, -6.6177], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(156.9276, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-110.6014])\n",
      "------- итерация 65 ------------------\n",
      "w1= tensor([1.6990], requires_grad=True) , pred =  tensor([ 0.2468,  0.2468, -6.5339], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(155.6084, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-111.5081])\n",
      "------- итерация 66 ------------------\n",
      "w1= tensor([1.7109], requires_grad=True) , pred =  tensor([ 0.2738,  0.2738, -6.4487], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(154.2740, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-112.4176])\n",
      "------- итерация 67 ------------------\n",
      "w1= tensor([1.7229], requires_grad=True) , pred =  tensor([ 0.3010,  0.3010, -6.3620], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(152.9245, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-113.3297])\n",
      "------- итерация 68 ------------------\n",
      "w1= tensor([1.7349], requires_grad=True) , pred =  tensor([ 0.3286,  0.3286, -6.2740], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(151.5598, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-114.2439])\n",
      "------- итерация 69 ------------------\n",
      "w1= tensor([1.7469], requires_grad=True) , pred =  tensor([ 0.3564,  0.3564, -6.1845], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(150.1798, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-115.1599])\n",
      "------- итерация 70 ------------------\n",
      "w1= tensor([1.7590], requires_grad=True) , pred =  tensor([ 0.3846,  0.3846, -6.0935], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(148.7844, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-116.0774])\n",
      "------- итерация 71 ------------------\n",
      "w1= tensor([1.7711], requires_grad=True) , pred =  tensor([ 0.4132,  0.4132, -6.0011], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(147.3736, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-116.9959])\n",
      "------- итерация 72 ------------------\n",
      "w1= tensor([1.7832], requires_grad=True) , pred =  tensor([ 0.4420,  0.4420, -5.9071], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(145.9474, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-117.9150])\n",
      "------- итерация 73 ------------------\n",
      "w1= tensor([1.7954], requires_grad=True) , pred =  tensor([ 0.4712,  0.4712, -5.8115], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(144.5057, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-118.8343])\n",
      "------- итерация 74 ------------------\n",
      "w1= tensor([1.8076], requires_grad=True) , pred =  tensor([ 0.5007,  0.5007, -5.7144], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(143.0484, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-119.7534])\n",
      "------- итерация 75 ------------------\n",
      "w1= tensor([1.8199], requires_grad=True) , pred =  tensor([ 0.5306,  0.5306, -5.6157], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(141.5756, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-120.6716])\n",
      "------- итерация 76 ------------------\n",
      "w1= tensor([1.8322], requires_grad=True) , pred =  tensor([ 0.5608,  0.5608, -5.5153], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(140.0873, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-121.5886])\n",
      "------- итерация 77 ------------------\n",
      "w1= tensor([1.8445], requires_grad=True) , pred =  tensor([ 0.5913,  0.5913, -5.4133], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(138.5835, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-122.5038])\n",
      "------- итерация 78 ------------------\n",
      "w1= tensor([1.8569], requires_grad=True) , pred =  tensor([ 0.6222,  0.6222, -5.3096], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(137.0641, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-123.4165])\n",
      "------- итерация 79 ------------------\n",
      "w1= tensor([1.8693], requires_grad=True) , pred =  tensor([ 0.6534,  0.6534, -5.2042], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(135.5292, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-124.3263])\n",
      "------- итерация 80 ------------------\n",
      "w1= tensor([1.8817], requires_grad=True) , pred =  tensor([ 0.6850,  0.6850, -5.0971], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(133.9788, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-125.2325])\n",
      "------- итерация 81 ------------------\n",
      "w1= tensor([1.8941], requires_grad=True) , pred =  tensor([ 0.7170,  0.7170, -4.9882], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(132.4131, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-126.1344])\n",
      "------- итерация 82 ------------------\n",
      "w1= tensor([1.9066], requires_grad=True) , pred =  tensor([ 0.7493,  0.7493, -4.8775], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(130.8319, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-127.0312])\n",
      "------- итерация 83 ------------------\n",
      "w1= tensor([1.9191], requires_grad=True) , pred =  tensor([ 0.7820,  0.7820, -4.7650], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(129.2355, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-127.9225])\n",
      "------- итерация 84 ------------------\n",
      "w1= tensor([1.9317], requires_grad=True) , pred =  tensor([ 0.8151,  0.8151, -4.6506], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(127.6240, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-128.8072])\n",
      "------- итерация 85 ------------------\n",
      "w1= tensor([1.9443], requires_grad=True) , pred =  tensor([ 0.8485,  0.8485, -4.5343], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(125.9973, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-129.6848])\n",
      "------- итерация 86 ------------------\n",
      "w1= tensor([1.9569], requires_grad=True) , pred =  tensor([ 0.8823,  0.8823, -4.4162], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(124.3557, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-130.5542])\n",
      "------- итерация 87 ------------------\n",
      "w1= tensor([1.9695], requires_grad=True) , pred =  tensor([ 0.9165,  0.9165, -4.2961], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(122.6994, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-131.4148])\n",
      "------- итерация 88 ------------------\n",
      "w1= tensor([1.9822], requires_grad=True) , pred =  tensor([ 0.9510,  0.9510, -4.1741], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(121.0283, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-132.2655])\n",
      "------- итерация 89 ------------------\n",
      "w1= tensor([1.9949], requires_grad=True) , pred =  tensor([ 0.9860,  0.9860, -4.0500], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(119.3429, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-133.1055])\n",
      "------- итерация 90 ------------------\n",
      "w1= tensor([2.0077], requires_grad=True) , pred =  tensor([ 1.0213,  1.0213, -3.9240], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(117.6431, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-133.9337])\n",
      "------- итерация 91 ------------------\n",
      "w1= tensor([2.0204], requires_grad=True) , pred =  tensor([ 1.0570,  1.0570, -3.7959], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(115.9293, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-134.7492])\n",
      "------- итерация 92 ------------------\n",
      "w1= tensor([2.0332], requires_grad=True) , pred =  tensor([ 1.0931,  1.0931, -3.6657], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(114.2018, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-135.5509])\n",
      "------- итерация 93 ------------------\n",
      "w1= tensor([2.0460], requires_grad=True) , pred =  tensor([ 1.1296,  1.1296, -3.5335], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(112.4607, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-136.3377])\n",
      "------- итерация 94 ------------------\n",
      "w1= tensor([2.0588], requires_grad=True) , pred =  tensor([ 1.1665,  1.1665, -3.3991], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(110.7063, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-137.1083])\n",
      "------- итерация 95 ------------------\n",
      "w1= tensor([2.0717], requires_grad=True) , pred =  tensor([ 1.2038,  1.2038, -3.2625], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(108.9390, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-137.8618])\n",
      "------- итерация 96 ------------------\n",
      "w1= tensor([2.0846], requires_grad=True) , pred =  tensor([ 1.2415,  1.2415, -3.1238], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(107.1590, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-138.5968])\n",
      "------- итерация 97 ------------------\n",
      "w1= tensor([2.0975], requires_grad=True) , pred =  tensor([ 1.2796,  1.2796, -2.9829], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(105.3669, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-139.3120])\n",
      "------- итерация 98 ------------------\n",
      "w1= tensor([2.1104], requires_grad=True) , pred =  tensor([ 1.3180,  1.3180, -2.8397], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(103.5629, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-140.0061])\n",
      "------- итерация 99 ------------------\n",
      "w1= tensor([2.1233], requires_grad=True) , pred =  tensor([ 1.3569,  1.3569, -2.6943], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(101.7474, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-140.6778])\n",
      "------- итерация 100 ------------------\n",
      "w1= tensor([2.1363], requires_grad=True) , pred =  tensor([ 1.3962,  1.3962, -2.5466], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(99.9210, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-141.3256])\n",
      "------- итерация 101 ------------------\n",
      "w1= tensor([2.1492], requires_grad=True) , pred =  tensor([ 1.4359,  1.4359, -2.3966], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(98.0840, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-141.9480])\n",
      "------- итерация 102 ------------------\n",
      "w1= tensor([2.1622], requires_grad=True) , pred =  tensor([ 1.4760,  1.4760, -2.2442], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(96.2370, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-142.5435])\n",
      "------- итерация 103 ------------------\n",
      "w1= tensor([2.1752], requires_grad=True) , pred =  tensor([ 1.5165,  1.5165, -2.0895], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(94.3806, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-143.1107])\n",
      "------- итерация 104 ------------------\n",
      "w1= tensor([2.1882], requires_grad=True) , pred =  tensor([ 1.5575,  1.5575, -1.9325], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(92.5152, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-143.6478])\n",
      "------- итерация 105 ------------------\n",
      "w1= tensor([2.2013], requires_grad=True) , pred =  tensor([ 1.5988,  1.5988, -1.7730], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(90.6415, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-144.1531])\n",
      "------- итерация 106 ------------------\n",
      "w1= tensor([2.2143], requires_grad=True) , pred =  tensor([ 1.6405,  1.6405, -1.6111], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(88.7602, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-144.6251])\n",
      "------- итерация 107 ------------------\n",
      "w1= tensor([2.2273], requires_grad=True) , pred =  tensor([ 1.6826,  1.6826, -1.4469], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(86.8718, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-145.0619])\n",
      "------- итерация 108 ------------------\n",
      "w1= tensor([2.2404], requires_grad=True) , pred =  tensor([ 1.7251,  1.7251, -1.2801], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(84.9772, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-145.4617])\n",
      "------- итерация 109 ------------------\n",
      "w1= tensor([2.2534], requires_grad=True) , pred =  tensor([ 1.7681,  1.7681, -1.1109], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(83.0770, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-145.8227])\n",
      "------- итерация 110 ------------------\n",
      "w1= tensor([2.2665], requires_grad=True) , pred =  tensor([ 1.8114,  1.8114, -0.9393], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(81.1720, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.1429])\n",
      "------- итерация 111 ------------------\n",
      "w1= tensor([2.2795], requires_grad=True) , pred =  tensor([ 1.8551,  1.8551, -0.7651], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(79.2631, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.4205])\n",
      "------- итерация 112 ------------------\n",
      "w1= tensor([2.2926], requires_grad=True) , pred =  tensor([ 1.8992,  1.8992, -0.5885], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(77.3511, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.6535])\n",
      "------- итерация 113 ------------------\n",
      "w1= tensor([2.3056], requires_grad=True) , pred =  tensor([ 1.9437,  1.9437, -0.4093], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(75.4368, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.8398])\n",
      "------- итерация 114 ------------------\n",
      "w1= tensor([2.3186], requires_grad=True) , pred =  tensor([ 1.9886,  1.9886, -0.2277], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(73.5213, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.9775])\n",
      "------- итерация 115 ------------------\n",
      "w1= tensor([2.3317], requires_grad=True) , pred =  tensor([ 2.0339,  2.0339, -0.0435], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(71.6055, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-147.0643])\n",
      "------- итерация 116 ------------------\n",
      "w1= tensor([2.3447], requires_grad=True) , pred =  tensor([2.0795, 2.0795, 0.1431], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(69.6905, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw1 =  tensor([-147.0983])\n",
      "------- итерация 117 ------------------\n",
      "w1= tensor([2.3577], requires_grad=True) , pred =  tensor([2.1255, 2.1255, 0.3323], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(67.7771, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-147.0772])\n",
      "------- итерация 118 ------------------\n",
      "w1= tensor([2.3707], requires_grad=True) , pred =  tensor([2.1719, 2.1719, 0.5240], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(65.8667, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.9990])\n",
      "------- итерация 119 ------------------\n",
      "w1= tensor([2.3837], requires_grad=True) , pred =  tensor([2.2186, 2.2186, 0.7181], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(63.9603, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.8613])\n",
      "------- итерация 120 ------------------\n",
      "w1= tensor([2.3966], requires_grad=True) , pred =  tensor([2.2657, 2.2657, 0.9148], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(62.0590, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.6621])\n",
      "------- итерация 121 ------------------\n",
      "w1= tensor([2.4095], requires_grad=True) , pred =  tensor([2.3131, 2.3131, 1.1138], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(60.1640, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.3991])\n",
      "------- итерация 122 ------------------\n",
      "w1= tensor([2.4225], requires_grad=True) , pred =  tensor([2.3608, 2.3608, 1.3154], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(58.2767, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-146.0702])\n",
      "------- итерация 123 ------------------\n",
      "w1= tensor([2.4353], requires_grad=True) , pred =  tensor([2.4089, 2.4089, 1.5193], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(56.3983, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-145.6731])\n",
      "------- итерация 124 ------------------\n",
      "w1= tensor([2.4482], requires_grad=True) , pred =  tensor([2.4572, 2.4572, 1.7257], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(54.5300, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-145.2057])\n",
      "------- итерация 125 ------------------\n",
      "w1= tensor([2.4610], requires_grad=True) , pred =  tensor([2.5059, 2.5059, 1.9344], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(52.6733, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-144.6658])\n",
      "------- итерация 126 ------------------\n",
      "w1= tensor([2.4738], requires_grad=True) , pred =  tensor([2.5549, 2.5549, 2.1454], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(50.8296, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-144.0513])\n",
      "------- итерация 127 ------------------\n",
      "w1= tensor([2.4865], requires_grad=True) , pred =  tensor([2.6041, 2.6041, 2.3587], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(49.0001, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-143.3601])\n",
      "------- итерация 128 ------------------\n",
      "w1= tensor([2.4992], requires_grad=True) , pred =  tensor([2.6536, 2.6536, 2.5742], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(47.1864, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-142.5903])\n",
      "------- итерация 129 ------------------\n",
      "w1= tensor([2.5118], requires_grad=True) , pred =  tensor([2.7033, 2.7033, 2.7919], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(45.3900, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-141.7398])\n",
      "------- итерация 130 ------------------\n",
      "w1= tensor([2.5244], requires_grad=True) , pred =  tensor([2.7533, 2.7533, 3.0118], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(43.6123, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-140.8068])\n",
      "------- итерация 131 ------------------\n",
      "w1= tensor([2.5369], requires_grad=True) , pred =  tensor([2.8035, 2.8035, 3.2336], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(41.8548, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-139.7895])\n",
      "------- итерация 132 ------------------\n",
      "w1= tensor([2.5494], requires_grad=True) , pred =  tensor([2.8538, 2.8538, 3.4575], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(40.1190, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-138.6862])\n",
      "------- итерация 133 ------------------\n",
      "w1= tensor([2.5618], requires_grad=True) , pred =  tensor([2.9044, 2.9044, 3.6832], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(38.4064, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-137.4954])\n",
      "------- итерация 134 ------------------\n",
      "w1= tensor([2.5741], requires_grad=True) , pred =  tensor([2.9550, 2.9550, 3.9108], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(36.7186, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-136.2156])\n",
      "------- итерация 135 ------------------\n",
      "w1= tensor([2.5864], requires_grad=True) , pred =  tensor([3.0059, 3.0059, 4.1401], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(35.0571, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-134.8455])\n",
      "------- итерация 136 ------------------\n",
      "w1= tensor([2.5986], requires_grad=True) , pred =  tensor([3.0568, 3.0568, 4.3710], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(33.4233, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-133.3840])\n",
      "------- итерация 137 ------------------\n",
      "w1= tensor([2.6107], requires_grad=True) , pred =  tensor([3.1078, 3.1078, 4.6034], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(31.8189, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-131.8302])\n",
      "------- итерация 138 ------------------\n",
      "w1= tensor([2.6227], requires_grad=True) , pred =  tensor([3.1589, 3.1589, 4.8372], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(30.2453, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-130.1834])\n",
      "------- итерация 139 ------------------\n",
      "w1= tensor([2.6346], requires_grad=True) , pred =  tensor([3.2099, 3.2099, 5.0723], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(28.7040, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-128.4431])\n",
      "------- итерация 140 ------------------\n",
      "w1= tensor([2.6464], requires_grad=True) , pred =  tensor([3.2610, 3.2610, 5.3086], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(27.1964, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-126.6089])\n",
      "------- итерация 141 ------------------\n",
      "w1= tensor([2.6581], requires_grad=True) , pred =  tensor([3.3121, 3.3121, 5.5458], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(25.7239, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-124.6809])\n",
      "------- итерация 142 ------------------\n",
      "w1= tensor([2.6697], requires_grad=True) , pred =  tensor([3.3631, 3.3631, 5.7839], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(24.2879, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-122.6593])\n",
      "------- итерация 143 ------------------\n",
      "w1= tensor([2.6812], requires_grad=True) , pred =  tensor([3.4140, 3.4140, 6.0226], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(22.8897, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-120.5447])\n",
      "------- итерация 144 ------------------\n",
      "w1= tensor([2.6926], requires_grad=True) , pred =  tensor([3.4648, 3.4648, 6.2619], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(21.5305, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-118.3380])\n",
      "------- итерация 145 ------------------\n",
      "w1= tensor([2.7039], requires_grad=True) , pred =  tensor([3.5154, 3.5154, 6.5016], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(20.2114, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-116.0403])\n",
      "------- итерация 146 ------------------\n",
      "w1= tensor([2.7150], requires_grad=True) , pred =  tensor([3.5659, 3.5659, 6.7414], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(18.9337, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-113.6532])\n",
      "------- итерация 147 ------------------\n",
      "w1= tensor([2.7260], requires_grad=True) , pred =  tensor([3.6161, 3.6161, 6.9811], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(17.6984, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-111.1787])\n",
      "------- итерация 148 ------------------\n",
      "w1= tensor([2.7368], requires_grad=True) , pred =  tensor([3.6660, 3.6660, 7.2207], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(16.5062, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-108.6189])\n",
      "------- итерация 149 ------------------\n",
      "w1= tensor([2.7475], requires_grad=True) , pred =  tensor([3.7156, 3.7156, 7.4597], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(15.3582, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-105.9768])\n",
      "------- итерация 150 ------------------\n",
      "w1= tensor([2.7581], requires_grad=True) , pred =  tensor([3.7649, 3.7649, 7.6981], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(14.2549, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-103.2551])\n",
      "------- итерация 151 ------------------\n",
      "w1= tensor([2.7684], requires_grad=True) , pred =  tensor([3.8138, 3.8138, 7.9356], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(13.1970, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-100.4576])\n",
      "------- итерация 152 ------------------\n",
      "w1= tensor([2.7787], requires_grad=True) , pred =  tensor([3.8622, 3.8622, 8.1720], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(12.1849, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-97.5881])\n",
      "------- итерация 153 ------------------\n",
      "w1= tensor([2.7887], requires_grad=True) , pred =  tensor([3.9101, 3.9101, 8.4070], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(11.2191, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-94.6509])\n",
      "------- итерация 154 ------------------\n",
      "w1= tensor([2.7986], requires_grad=True) , pred =  tensor([3.9576, 3.9576, 8.6404], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(10.2996, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-91.6508])\n",
      "------- итерация 155 ------------------\n",
      "w1= tensor([2.8083], requires_grad=True) , pred =  tensor([4.0044, 4.0044, 8.8719], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(9.4267, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-88.5930])\n",
      "------- итерация 156 ------------------\n",
      "w1= tensor([2.8178], requires_grad=True) , pred =  tensor([4.0507, 4.0507, 9.1012], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(8.6001, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-85.4830])\n",
      "------- итерация 157 ------------------\n",
      "w1= tensor([2.8271], requires_grad=True) , pred =  tensor([4.0963, 4.0963, 9.3282], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.8198, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-82.3269])\n",
      "------- итерация 158 ------------------\n",
      "w1= tensor([2.8362], requires_grad=True) , pred =  tensor([4.1412, 4.1412, 9.5524], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.0853, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-79.1310])\n",
      "------- итерация 159 ------------------\n",
      "w1= tensor([2.8451], requires_grad=True) , pred =  tensor([4.1853, 4.1853, 9.7738], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(6.3961, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-75.9019])\n",
      "------- итерация 160 ------------------\n",
      "w1= tensor([2.8537], requires_grad=True) , pred =  tensor([4.2287, 4.2287, 9.9919], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(5.7515, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-72.6468])\n",
      "------- итерация 161 ------------------\n",
      "w1= tensor([2.8622], requires_grad=True) , pred =  tensor([ 4.2712,  4.2712, 10.2066], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(5.1508, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-69.3730])\n",
      "------- итерация 162 ------------------\n",
      "w1= tensor([2.8704], requires_grad=True) , pred =  tensor([ 4.3128,  4.3128, 10.4175], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.5929, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-66.0882])\n",
      "------- итерация 163 ------------------\n",
      "w1= tensor([2.8784], requires_grad=True) , pred =  tensor([ 4.3535,  4.3535, 10.6244], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.0768, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-62.8001])\n",
      "------- итерация 164 ------------------\n",
      "w1= tensor([2.8862], requires_grad=True) , pred =  tensor([ 4.3932,  4.3932, 10.8271], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.6012, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-59.5167])\n",
      "------- итерация 165 ------------------\n",
      "w1= tensor([2.8937], requires_grad=True) , pred =  tensor([ 4.4320,  4.4320, 11.0252], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.1648, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-56.2463])\n",
      "------- итерация 166 ------------------\n",
      "w1= tensor([2.9010], requires_grad=True) , pred =  tensor([ 4.4697,  4.4697, 11.2186], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.7662, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-52.9970])\n",
      "------- итерация 167 ------------------\n",
      "w1= tensor([2.9081], requires_grad=True) , pred =  tensor([ 4.5063,  4.5063, 11.4070], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.4037, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-49.7769])\n",
      "------- итерация 168 ------------------\n",
      "w1= tensor([2.9149], requires_grad=True) , pred =  tensor([ 4.5418,  4.5418, 11.5902], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.0757, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-46.5945])\n",
      "------- итерация 169 ------------------\n",
      "w1= tensor([2.9215], requires_grad=True) , pred =  tensor([ 4.5761,  4.5761, 11.7680], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.7804, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-43.4577])\n",
      "------- итерация 170 ------------------\n",
      "w1= tensor([2.9278], requires_grad=True) , pred =  tensor([ 4.6093,  4.6093, 11.9401], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.5162, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-40.3744])\n",
      "------- итерация 171 ------------------\n",
      "w1= tensor([2.9338], requires_grad=True) , pred =  tensor([ 4.6413,  4.6413, 12.1064], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.2810, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-37.3524])\n",
      "------- итерация 172 ------------------\n",
      "w1= tensor([2.9396], requires_grad=True) , pred =  tensor([ 4.6720,  4.6720, 12.2668], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.0730, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-34.3990])\n",
      "------- итерация 173 ------------------\n",
      "w1= tensor([2.9452], requires_grad=True) , pred =  tensor([ 4.7016,  4.7016, 12.4211], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.8904, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-31.5215])\n",
      "------- итерация 174 ------------------\n",
      "w1= tensor([2.9504], requires_grad=True) , pred =  tensor([ 4.7298,  4.7298, 12.5691], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.7311, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-28.7262])\n",
      "------- итерация 175 ------------------\n",
      "w1= tensor([2.9555], requires_grad=True) , pred =  tensor([ 4.7568,  4.7568, 12.7108], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.5934, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-26.0195])\n",
      "------- итерация 176 ------------------\n",
      "w1= tensor([2.9602], requires_grad=True) , pred =  tensor([ 4.7826,  4.7826, 12.8461], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.4753, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-23.4070])\n",
      "------- итерация 177 ------------------\n",
      "w1= tensor([2.9648], requires_grad=True) , pred =  tensor([ 4.8070,  4.8070, 12.9749], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.3751, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-20.8940])\n",
      "------- итерация 178 ------------------\n",
      "w1= tensor([2.9690], requires_grad=True) , pred =  tensor([ 4.8302,  4.8302, 13.0972], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.2909, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-18.4850])\n",
      "------- итерация 179 ------------------\n",
      "w1= tensor([2.9731], requires_grad=True) , pred =  tensor([ 4.8521,  4.8521, 13.2129], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.2211, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-16.1838])\n",
      "------- итерация 180 ------------------\n",
      "w1= tensor([2.9769], requires_grad=True) , pred =  tensor([ 4.8727,  4.8727, 13.3222], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.1640, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-13.9938])\n",
      "------- итерация 181 ------------------\n",
      "w1= tensor([2.9804], requires_grad=True) , pred =  tensor([ 4.8921,  4.8921, 13.4249], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.1180, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-11.9178])\n",
      "------- итерация 182 ------------------\n",
      "w1= tensor([2.9837], requires_grad=True) , pred =  tensor([ 4.9102,  4.9102, 13.5212], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0818, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-9.9574])\n",
      "------- итерация 183 ------------------\n",
      "w1= tensor([2.9868], requires_grad=True) , pred =  tensor([ 4.9271,  4.9271, 13.6111], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0540, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-8.1143])\n",
      "------- итерация 184 ------------------\n",
      "w1= tensor([2.9896], requires_grad=True) , pred =  tensor([ 4.9428,  4.9428, 13.6947], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0332, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-6.3888])\n",
      "------- итерация 185 ------------------\n",
      "w1= tensor([2.9923], requires_grad=True) , pred =  tensor([ 4.9573,  4.9573, 13.7722], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(0.0185, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-4.7810])\n",
      "------- итерация 186 ------------------\n",
      "w1= tensor([2.9947], requires_grad=True) , pred =  tensor([ 4.9707,  4.9707, 13.8436], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0087, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-3.2904])\n",
      "------- итерация 187 ------------------\n",
      "w1= tensor([2.9969], requires_grad=True) , pred =  tensor([ 4.9830,  4.9830, 13.9092], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-1.9158])\n",
      "------- итерация 188 ------------------\n",
      "w1= tensor([2.9990], requires_grad=True) , pred =  tensor([ 4.9942,  4.9942, 13.9690], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.6551])\n",
      "------- итерация 189 ------------------\n",
      "w1= tensor([3.0008], requires_grad=True) , pred =  tensor([ 5.0044,  5.0044, 14.0233], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.4937])\n",
      "------- итерация 190 ------------------\n",
      "w1= tensor([3.0024], requires_grad=True) , pred =  tensor([ 5.0135,  5.0135, 14.0723], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([1.5335])\n",
      "------- итерация 191 ------------------\n",
      "w1= tensor([3.0039], requires_grad=True) , pred =  tensor([ 5.0217,  5.0217, 14.1161], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([2.4675])\n",
      "------- итерация 192 ------------------\n",
      "w1= tensor([3.0052], requires_grad=True) , pred =  tensor([ 5.0290,  5.0290, 14.1551], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([3.2994])\n",
      "------- итерация 193 ------------------\n",
      "w1= tensor([3.0064], requires_grad=True) , pred =  tensor([ 5.0354,  5.0354, 14.1893], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0128, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([4.0331])\n",
      "------- итерация 194 ------------------\n",
      "w1= tensor([3.0074], requires_grad=True) , pred =  tensor([ 5.0409,  5.0409, 14.2191], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0171, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([4.6727])\n",
      "------- итерация 195 ------------------\n",
      "w1= tensor([3.0082], requires_grad=True) , pred =  tensor([ 5.0457,  5.0457, 14.2447], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0214, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([5.2230])\n",
      "------- итерация 196 ------------------\n",
      "w1= tensor([3.0089], requires_grad=True) , pred =  tensor([ 5.0497,  5.0497, 14.2663], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0253, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([5.6884])\n",
      "------- итерация 197 ------------------\n",
      "w1= tensor([3.0095], requires_grad=True) , pred =  tensor([ 5.0530,  5.0530, 14.2842], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0288, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.0738])\n",
      "------- итерация 198 ------------------\n",
      "w1= tensor([3.0100], requires_grad=True) , pred =  tensor([ 5.0557,  5.0557, 14.2986], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0318, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.3843])\n",
      "------- итерация 199 ------------------\n",
      "w1= tensor([3.0104], requires_grad=True) , pred =  tensor([ 5.0578,  5.0578, 14.3097], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0342, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.6247])\n",
      "------- итерация 200 ------------------\n",
      "w1= tensor([3.0107], requires_grad=True) , pred =  tensor([ 5.0593,  5.0593, 14.3178], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0360, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.8001])\n",
      "------- итерация 201 ------------------\n",
      "w1= tensor([3.0108], requires_grad=True) , pred =  tensor([ 5.0603,  5.0603, 14.3231], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0372, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.9154])\n",
      "------- итерация 202 ------------------\n",
      "w1= tensor([3.0109], requires_grad=True) , pred =  tensor([ 5.0608,  5.0608, 14.3259], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0379, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.9756])\n",
      "------- итерация 203 ------------------\n",
      "w1= tensor([3.0109], requires_grad=True) , pred =  tensor([ 5.0609,  5.0609, 14.3264], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0380, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.9855])\n",
      "------- итерация 204 ------------------\n",
      "w1= tensor([3.0109], requires_grad=True) , pred =  tensor([ 5.0606,  5.0606, 14.3247], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0376, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.9497])\n",
      "------- итерация 205 ------------------\n",
      "w1= tensor([3.0108], requires_grad=True) , pred =  tensor([ 5.0599,  5.0599, 14.3212], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0368, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.8728])\n",
      "------- итерация 206 ------------------\n",
      "w1= tensor([3.0106], requires_grad=True) , pred =  tensor([ 5.0589,  5.0589, 14.3159], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0356, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.7595])\n",
      "------- итерация 207 ------------------\n",
      "w1= tensor([3.0104], requires_grad=True) , pred =  tensor([ 5.0577,  5.0577, 14.3092], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0341, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.6138])\n",
      "------- итерация 208 ------------------\n",
      "w1= tensor([3.0101], requires_grad=True) , pred =  tensor([ 5.0562,  5.0562, 14.3011], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0323, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.4398])\n",
      "------- итерация 209 ------------------\n",
      "w1= tensor([3.0098], requires_grad=True) , pred =  tensor([ 5.0545,  5.0545, 14.2920], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0304, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.2413])\n",
      "------- итерация 210 ------------------\n",
      "w1= tensor([3.0095], requires_grad=True) , pred =  tensor([ 5.0526,  5.0526, 14.2818], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0283, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([6.0220])\n",
      "------- итерация 211 ------------------\n",
      "w1= tensor([3.0091], requires_grad=True) , pred =  tensor([ 5.0505,  5.0505, 14.2708], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0262, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([5.7854])\n",
      "------- итерация 212 ------------------\n",
      "w1= tensor([3.0087], requires_grad=True) , pred =  tensor([ 5.0484,  5.0484, 14.2592], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0240, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([5.5346])\n",
      "------- итерация 213 ------------------\n",
      "w1= tensor([3.0083], requires_grad=True) , pred =  tensor([ 5.0461,  5.0461, 14.2470], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0218, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([5.2726])\n",
      "------- итерация 214 ------------------\n",
      "w1= tensor([3.0079], requires_grad=True) , pred =  tensor([ 5.0438,  5.0438, 14.2345], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0196, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([5.0024])\n",
      "------- итерация 215 ------------------\n",
      "w1= tensor([3.0074], requires_grad=True) , pred =  tensor([ 5.0414,  5.0414, 14.2216], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0175, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([4.7262])\n",
      "------- итерация 216 ------------------\n",
      "w1= tensor([3.0070], requires_grad=True) , pred =  tensor([ 5.0389,  5.0389, 14.2086], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0155, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([4.4466])\n",
      "------- итерация 217 ------------------\n",
      "w1= tensor([3.0066], requires_grad=True) , pred =  tensor([ 5.0365,  5.0365, 14.1955], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0136, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([4.1657])\n",
      "------- итерация 218 ------------------\n",
      "w1= tensor([3.0061], requires_grad=True) , pred =  tensor([ 5.0341,  5.0341, 14.1825], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0119, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([3.8853])\n",
      "------- итерация 219 ------------------\n",
      "w1= tensor([3.0057], requires_grad=True) , pred =  tensor([ 5.0316,  5.0316, 14.1695], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([3.6073])\n",
      "------- итерация 220 ------------------\n",
      "w1= tensor([3.0053], requires_grad=True) , pred =  tensor([ 5.0293,  5.0293, 14.1567], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0088, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([3.3332])\n",
      "------- итерация 221 ------------------\n",
      "w1= tensor([3.0048], requires_grad=True) , pred =  tensor([ 5.0269,  5.0269, 14.1441], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0074, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([3.0643])\n",
      "------- итерация 222 ------------------\n",
      "w1= tensor([3.0044], requires_grad=True) , pred =  tensor([ 5.0246,  5.0246, 14.1318], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([2.8019])\n",
      "------- итерация 223 ------------------\n",
      "w1= tensor([3.0040], requires_grad=True) , pred =  tensor([ 5.0224,  5.0224, 14.1199], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([2.5471])\n",
      "------- итерация 224 ------------------\n",
      "w1= tensor([3.0036], requires_grad=True) , pred =  tensor([ 5.0202,  5.0202, 14.1083], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([2.3006])\n",
      "------- итерация 225 ------------------\n",
      "w1= tensor([3.0033], requires_grad=True) , pred =  tensor([ 5.0182,  5.0182, 14.0972], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([2.0634])\n",
      "------- итерация 226 ------------------\n",
      "w1= tensor([3.0029], requires_grad=True) , pred =  tensor([ 5.0162,  5.0162, 14.0865], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([1.8361])\n",
      "------- итерация 227 ------------------\n",
      "w1= tensor([3.0026], requires_grad=True) , pred =  tensor([ 5.0143,  5.0143, 14.0763], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([1.6190])\n",
      "------- итерация 228 ------------------\n",
      "w1= tensor([3.0022], requires_grad=True) , pred =  tensor([ 5.0124,  5.0124, 14.0666], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([1.4128])\n",
      "------- итерация 229 ------------------\n",
      "w1= tensor([3.0019], requires_grad=True) , pred =  tensor([ 5.0107,  5.0107, 14.0574], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([1.2176])\n",
      "------- итерация 230 ------------------\n",
      "w1= tensor([3.0016], requires_grad=True) , pred =  tensor([ 5.0091,  5.0091, 14.0488], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([1.0335])\n",
      "------- итерация 231 ------------------\n",
      "w1= tensor([3.0014], requires_grad=True) , pred =  tensor([ 5.0076,  5.0076, 14.0406], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.8607])\n",
      "------- итерация 232 ------------------\n",
      "w1= tensor([3.0011], requires_grad=True) , pred =  tensor([ 5.0062,  5.0062, 14.0330], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.6993])\n",
      "------- итерация 233 ------------------\n",
      "w1= tensor([3.0009], requires_grad=True) , pred =  tensor([ 5.0048,  5.0048, 14.0259], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.5490])\n",
      "------- итерация 234 ------------------\n",
      "w1= tensor([3.0007], requires_grad=True) , pred =  tensor([ 5.0036,  5.0036, 14.0194], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.4100])\n",
      "------- итерация 235 ------------------\n",
      "w1= tensor([3.0004], requires_grad=True) , pred =  tensor([ 5.0025,  5.0025, 14.0133], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(6.3208e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.2818])\n",
      "------- итерация 236 ------------------\n",
      "w1= tensor([3.0003], requires_grad=True) , pred =  tensor([ 5.0015,  5.0015, 14.0078], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.1512e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.1644])\n",
      "------- итерация 237 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0027], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.6162e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0573])\n",
      "------- итерация 238 ------------------\n",
      "w1= tensor([2.9999], requires_grad=True) , pred =  tensor([ 4.9997,  4.9997, 13.9981], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.2435e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0395])\n",
      "------- итерация 239 ------------------\n",
      "w1= tensor([2.9998], requires_grad=True) , pred =  tensor([ 4.9989,  4.9989, 13.9940], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.2759e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.1265])\n",
      "------- итерация 240 ------------------\n",
      "w1= tensor([2.9997], requires_grad=True) , pred =  tensor([ 4.9982,  4.9982, 13.9903], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.3219e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.2041])\n",
      "------- итерация 241 ------------------\n",
      "w1= tensor([2.9996], requires_grad=True) , pred =  tensor([ 4.9976,  4.9976, 13.9871], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(5.9307e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.2727])\n",
      "------- итерация 242 ------------------\n",
      "w1= tensor([2.9995], requires_grad=True) , pred =  tensor([ 4.9971,  4.9971, 13.9843], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(8.8329e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.3328])\n",
      "------- итерация 243 ------------------\n",
      "w1= tensor([2.9994], requires_grad=True) , pred =  tensor([ 4.9966,  4.9966, 13.9818], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.3846])\n",
      "------- итерация 244 ------------------\n",
      "w1= tensor([2.9993], requires_grad=True) , pred =  tensor([ 4.9962,  4.9962, 13.9797], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.4288])\n",
      "------- итерация 245 ------------------\n",
      "w1= tensor([2.9993], requires_grad=True) , pred =  tensor([ 4.9959,  4.9959, 13.9780], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.4657])\n",
      "------- итерация 246 ------------------\n",
      "w1= tensor([2.9992], requires_grad=True) , pred =  tensor([ 4.9956,  4.9956, 13.9765], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.4958])\n",
      "------- итерация 247 ------------------\n",
      "w1= tensor([2.9992], requires_grad=True) , pred =  tensor([ 4.9954,  4.9954, 13.9754], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5195])\n",
      "------- итерация 248 ------------------\n",
      "w1= tensor([2.9991], requires_grad=True) , pred =  tensor([ 4.9952,  4.9952, 13.9746], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5375])\n",
      "------- итерация 249 ------------------\n",
      "w1= tensor([2.9991], requires_grad=True) , pred =  tensor([ 4.9951,  4.9951, 13.9740], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5498])\n",
      "------- итерация 250 ------------------\n",
      "w1= tensor([2.9991], requires_grad=True) , pred =  tensor([ 4.9951,  4.9951, 13.9736], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5573])\n",
      "------- итерация 251 ------------------\n",
      "w1= tensor([2.9991], requires_grad=True) , pred =  tensor([ 4.9950,  4.9950, 13.9735], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5601])\n",
      "------- итерация 252 ------------------\n",
      "w1= tensor([2.9991], requires_grad=True) , pred =  tensor([ 4.9951,  4.9951, 13.9736], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5588])\n",
      "------- итерация 253 ------------------\n",
      "w1= tensor([2.9991], requires_grad=True) , pred =  tensor([ 4.9951,  4.9951, 13.9738], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5537])\n",
      "------- итерация 254 ------------------\n",
      "w1= tensor([2.9991], requires_grad=True) , pred =  tensor([ 4.9952,  4.9952, 13.9742], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5454])\n",
      "------- итерация 255 ------------------\n",
      "w1= tensor([2.9991], requires_grad=True) , pred =  tensor([ 4.9953,  4.9953, 13.9747], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5340])\n",
      "------- итерация 256 ------------------\n",
      "w1= tensor([2.9992], requires_grad=True) , pred =  tensor([ 4.9954,  4.9954, 13.9754], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5200])\n",
      "------- итерация 257 ------------------\n",
      "w1= tensor([2.9992], requires_grad=True) , pred =  tensor([ 4.9955,  4.9955, 13.9762], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.5038])\n",
      "------- итерация 258 ------------------\n",
      "w1= tensor([2.9992], requires_grad=True) , pred =  tensor([ 4.9957,  4.9957, 13.9770], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.4855])\n",
      "------- итерация 259 ------------------\n",
      "w1= tensor([2.9993], requires_grad=True) , pred =  tensor([ 4.9959,  4.9959, 13.9780], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.4657])\n",
      "------- итерация 260 ------------------\n",
      "w1= tensor([2.9993], requires_grad=True) , pred =  tensor([ 4.9961,  4.9961, 13.9790], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.4445])\n",
      "------- итерация 261 ------------------\n",
      "w1= tensor([2.9993], requires_grad=True) , pred =  tensor([ 4.9963,  4.9963, 13.9800], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.4222])\n",
      "------- итерация 262 ------------------\n",
      "w1= tensor([2.9994], requires_grad=True) , pred =  tensor([ 4.9965,  4.9965, 13.9811], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.3992])\n",
      "------- итерация 263 ------------------\n",
      "w1= tensor([2.9994], requires_grad=True) , pred =  tensor([ 4.9967,  4.9967, 13.9822], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.3757])\n",
      "------- итерация 264 ------------------\n",
      "w1= tensor([2.9994], requires_grad=True) , pred =  tensor([ 4.9969,  4.9969, 13.9834], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(9.8610e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.3516])\n",
      "------- итерация 265 ------------------\n",
      "w1= tensor([2.9995], requires_grad=True) , pred =  tensor([ 4.9971,  4.9971, 13.9845], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(8.5503e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.3274])\n",
      "------- итерация 266 ------------------\n",
      "w1= tensor([2.9995], requires_grad=True) , pred =  tensor([ 4.9973,  4.9973, 13.9857], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.3313e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.3032])\n",
      "------- итерация 267 ------------------\n",
      "w1= tensor([2.9996], requires_grad=True) , pred =  tensor([ 4.9975,  4.9975, 13.9868], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(6.2218e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.2793])\n",
      "------- итерация 268 ------------------\n",
      "w1= tensor([2.9996], requires_grad=True) , pred =  tensor([ 4.9977,  4.9977, 13.9879], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(5.2134e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.2557])\n",
      "------- итерация 269 ------------------\n",
      "w1= tensor([2.9996], requires_grad=True) , pred =  tensor([ 4.9979,  4.9979, 13.9890], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.3106e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.2325])\n",
      "------- итерация 270 ------------------\n",
      "w1= tensor([2.9997], requires_grad=True) , pred =  tensor([ 4.9981,  4.9981, 13.9901], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.5150e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.2100])\n",
      "------- итерация 271 ------------------\n",
      "w1= tensor([2.9997], requires_grad=True) , pred =  tensor([ 4.9983,  4.9983, 13.9911], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.8223e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.1882])\n",
      "------- итерация 272 ------------------\n",
      "w1= tensor([2.9997], requires_grad=True) , pred =  tensor([ 4.9985,  4.9985, 13.9921], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.2248e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.1671])\n",
      "------- итерация 273 ------------------\n",
      "w1= tensor([2.9998], requires_grad=True) , pred =  tensor([ 4.9987,  4.9987, 13.9931], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.7199e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.1469])\n",
      "------- итерация 274 ------------------\n",
      "w1= tensor([2.9998], requires_grad=True) , pred =  tensor([ 4.9989,  4.9989, 13.9940], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.2972e-05, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.1276])\n",
      "------- итерация 275 ------------------\n",
      "w1= tensor([2.9998], requires_grad=True) , pred =  tensor([ 4.9990,  4.9990, 13.9948], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(9.5006e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.1092])\n",
      "------- итерация 276 ------------------\n",
      "w1= tensor([2.9999], requires_grad=True) , pred =  tensor([ 4.9992,  4.9992, 13.9957], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(6.7209e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0918])\n",
      "------- итерация 277 ------------------\n",
      "w1= tensor([2.9999], requires_grad=True) , pred =  tensor([ 4.9993,  4.9993, 13.9964], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.5467e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0755])\n",
      "------- итерация 278 ------------------\n",
      "w1= tensor([2.9999], requires_grad=True) , pred =  tensor([ 4.9995,  4.9995, 13.9972], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.8958e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0603])\n",
      "------- итерация 279 ------------------\n",
      "w1= tensor([2.9999], requires_grad=True) , pred =  tensor([ 4.9996,  4.9996, 13.9978], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.6921e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0461])\n",
      "------- итерация 280 ------------------\n",
      "w1= tensor([2.9999], requires_grad=True) , pred =  tensor([ 4.9997,  4.9997, 13.9984], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(8.6386e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0329])\n",
      "------- итерация 281 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9998,  4.9998, 13.9990], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.4410e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0208])\n",
      "------- итерация 282 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9995], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.5344e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0097])\n",
      "------- итерация 283 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(6.4877e-11, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0003])\n",
      "------- итерация 284 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0001,  5.0001, 14.0004], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.0990e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0094])\n",
      "------- итерация 285 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0002,  5.0002, 14.0008], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.4432e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0175])\n",
      "------- итерация 286 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0002,  5.0002, 14.0012], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.8599e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0247])\n",
      "------- итерация 287 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0003,  5.0003, 14.0015], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.6520e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0310])\n",
      "------- итерация 288 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0003,  5.0003, 14.0017], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.0533e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0364])\n",
      "------- итерация 289 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0019], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.3393e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0410])\n",
      "------- итерация 290 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0021], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.6044e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0449])\n",
      "------- итерация 291 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0023], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.8373e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0480])\n",
      "------- итерация 292 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0024], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.0373e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0506])\n",
      "------- итерация 293 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0025], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.1857e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0524])\n",
      "------- итерация 294 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0025], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.2987e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0537])\n",
      "------- итерация 295 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0026], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.3647e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0545])\n",
      "------- итерация 296 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0026], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.3889e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0548])\n",
      "------- итерация 297 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0026], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.3751e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0546])\n",
      "------- итерация 298 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0026], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.3258e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0540])\n",
      "------- итерация 299 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0025], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.2469e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0531])\n",
      "------- итерация 300 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0005,  5.0005, 14.0025], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.1489e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0519])\n",
      "------- итерация 301 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0024], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.0270e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0504])\n",
      "------- итерация 302 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0023], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.8841e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0486])\n",
      "------- итерация 303 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0022], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.7370e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0467])\n",
      "------- итерация 304 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0021], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.5841e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0446])\n",
      "------- итерация 305 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0020], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.4276e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0423])\n",
      "------- итерация 306 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0004,  5.0004, 14.0019], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.2715e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0400])\n",
      "------- итерация 307 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0003,  5.0003, 14.0018], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.1245e-06, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0376])\n",
      "------- итерация 308 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0003,  5.0003, 14.0017], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(9.7730e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0350])\n",
      "------- итерация 309 ------------------\n",
      "w1= tensor([3.0001], requires_grad=True) , pred =  tensor([ 5.0003,  5.0003, 14.0015], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(8.4077e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0325])\n",
      "------- итерация 310 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0003,  5.0003, 14.0014], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.1417e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0299])\n",
      "------- итерация 311 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0002,  5.0002, 14.0013], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(5.9820e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0274])\n",
      "------- итерация 312 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0002,  5.0002, 14.0012], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.9223e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0249])\n",
      "------- итерация 313 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0002,  5.0002, 14.0011], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.0111e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0224])\n",
      "------- итерация 314 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0002,  5.0002, 14.0009], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.2051e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0201])\n",
      "------- итерация 315 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0002,  5.0002, 14.0008], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.5235e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0178])\n",
      "------- итерация 316 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0001,  5.0001, 14.0007], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.9325e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0156])\n",
      "------- итерация 317 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0001,  5.0001, 14.0006], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.4475e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0135])\n",
      "------- итерация 318 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0001,  5.0001, 14.0005], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.0312e-07, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0114])\n",
      "------- итерация 319 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0001,  5.0001, 14.0004], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.0990e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0094])\n",
      "------- итерация 320 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0001,  5.0001, 14.0004], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.6374e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0076])\n",
      "------- итерация 321 ------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0001,  5.0001, 14.0003], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.8396e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0060])\n",
      "------- итерация 322 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0002], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.6011e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0045])\n",
      "------- итерация 323 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0001], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.1159e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0030])\n",
      "------- итерация 324 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0001], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.1749e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0017])\n",
      "------- итерация 325 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.5643e-10, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.0004])\n",
      "------- итерация 326 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.9119e-10, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0006])\n",
      "------- итерация 327 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.1749e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0017])\n",
      "------- итерация 328 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(5.1479e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0025])\n",
      "------- итерация 329 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(8.7180e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0033])\n",
      "------- итерация 330 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.1962e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0039])\n",
      "------- итерация 331 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.5985e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0045])\n",
      "------- итерация 332 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.9304e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0049])\n",
      "------- итерация 333 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.2967e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0054])\n",
      "------- итерация 334 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.5780e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0057])\n",
      "------- итерация 335 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.8430e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0060])\n",
      "------- итерация 336 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.9987e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0061])\n",
      "------- итерация 337 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.1551e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0063])\n",
      "------- итерация 338 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.1551e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0063])\n",
      "------- итерация 339 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.1551e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0063])\n",
      "------- итерация 340 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.1551e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0063])\n",
      "------- итерация 341 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.9987e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0061])\n",
      "------- итерация 342 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.8430e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0060])\n",
      "------- итерация 343 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.7264e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0058])\n",
      "------- итерация 344 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 4.9999,  4.9999, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.5780e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0057])\n",
      "------- итерация 345 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9997], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.2967e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0054])\n",
      "------- итерация 346 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.0592e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0051])\n",
      "------- итерация 347 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.8373e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0048])\n",
      "------- итерация 348 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.5985e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0045])\n",
      "------- итерация 349 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.4038e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0042])\n",
      "------- итерация 350 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.1962e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0039])\n",
      "------- итерация 351 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.0286e-08, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0036])\n",
      "------- итерация 352 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9998], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(8.7180e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0033])\n",
      "------- итерация 353 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(7.0991e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0030])\n",
      "------- итерация 354 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(5.8226e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0027])\n",
      "------- итерация 355 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.5147e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0024])\n",
      "------- итерация 356 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(3.5096e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0021])\n",
      "------- итерация 357 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.5128e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0018])\n",
      "------- итерация 358 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.7790e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0015])\n",
      "------- итерация 359 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 13.9999], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.1648e-09, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0012])\n",
      "------- итерация 360 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(6.3073e-10, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0009])\n",
      "------- итерация 361 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(4.6748e-10, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0008])\n",
      "------- итерация 362 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.9119e-10, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0006])\n",
      "------- итерация 363 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(1.5643e-10, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0004])\n",
      "------- итерация 364 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(6.4877e-11, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0003])\n",
      "------- итерация 365 ------------------\n",
      "w1= tensor([3.0000], requires_grad=True) , pred =  tensor([ 5.0000,  5.0000, 14.0000], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(2.0767e-11, grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([-0.0002])\n",
      "------- итерация 366 ------------------\n",
      "w1= tensor([3.], requires_grad=True) , pred =  tensor([ 5.,  5., 14.], grad_fn=<AddBackward0>)\n",
      "loss =  tensor(0., grad_fn=<MseLossBackward0>)\n",
      "dL/dw1 =  tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# Давайте теперь пооптимизируем: возьмите функцию y = x**w1 - 2 * x**2 + 5\n",
    "# Посчитайте \n",
    "#\n",
    "# Зададим y и x и подберем w1 по близости функции к целевому y.\n",
    "from torch import optim\n",
    "from torch import nn \n",
    "\n",
    "x = torch.tensor([2., 2., 3.])\n",
    "y = x ** 3 - 2 * x ** 2 + 5 # будем искать w1 = 3\n",
    "\n",
    "print('x = ', x)\n",
    "print('y = ', y)\n",
    "\n",
    "\n",
    "w1 = Variable(torch.tensor([1.]), requires_grad = True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam([w1], lr=0.01)\n",
    "\n",
    "for i in range(1000):\n",
    "    print(f'------- итерация {i} ------------------')\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = x ** w1 - 2 * x ** 2 + 5\n",
    "    print('w1=', w1, ', pred = ', pred)\n",
    "\n",
    "    loss = criterion(pred, y)\n",
    "    print('loss = ', loss)\n",
    "    loss.backward()\n",
    "    print('dL/dw1 = ', w1.grad)\n",
    "    optimizer.step()\n",
    "    if abs(w1.grad) < 0.0001:\n",
    "        break\n",
    "        \n",
    "# найдено значение 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
